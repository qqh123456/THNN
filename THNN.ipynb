{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57105e2d-d44e-4d4f-af27-43ff58f16a98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T03:45:30.368798Z",
     "iopub.status.busy": "2023-05-28T03:45:30.368359Z",
     "iopub.status.idle": "2023-05-28T03:45:32.652835Z",
     "shell.execute_reply": "2023-05-28T03:45:32.652409Z",
     "shell.execute_reply.started": "2023-05-28T03:45:30.368762Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, os\n",
    "import datetime\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler,normalize\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dense, Input, Concatenate, BatchNormalization, Activation,LayerNormalization\n",
    "from keras.layers import Lambda, Embedding, GRU, Bidirectional, TimeDistributed, concatenate,Flatten,GlobalAveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "from keras import initializers\n",
    "from word2vecReader import Word2Vec\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "import pickle\n",
    "# from tensorflow.python.keras.optimizers import adam_v2\n",
    "# from tensorflow.python.keras.optimizers import rmsprop_v2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from  keras import layers\n",
    "from time import process_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e07ca67c-4ad5-4cf8-9495-47eb398d6b68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T03:45:56.515661Z",
     "iopub.status.busy": "2023-05-28T03:45:56.515192Z",
     "iopub.status.idle": "2023-05-28T03:45:56.523048Z",
     "shell.execute_reply": "2023-05-28T03:45:56.521792Z",
     "shell.execute_reply.started": "2023-05-28T03:45:56.515623Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "255013ef-c12c-4ce4-9c62-4a62726874e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T03:45:57.172764Z",
     "iopub.status.busy": "2023-05-28T03:45:57.171992Z",
     "iopub.status.idle": "2023-05-28T03:45:57.189493Z",
     "shell.execute_reply": "2023-05-28T03:45:57.187896Z",
     "shell.execute_reply.started": "2023-05-28T03:45:57.172704Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\lib\\site-packages\\keras\\backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "K.set_learning_phase(1)\n",
    "np.random.seed(0)\n",
    "MAX_SENT_LENGTH = 20  #number of words in a sentence\n",
    "MAX_NB_WORDS = 20000\n",
    "POST_DIM = 400\n",
    "INFO_DIM = 30\n",
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "209ddfce-f0ed-4f92-b963-ad562cf97990",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T03:45:57.850476Z",
     "iopub.status.busy": "2023-05-28T03:45:57.849987Z",
     "iopub.status.idle": "2023-05-28T03:45:57.892066Z",
     "shell.execute_reply": "2023-05-28T03:45:57.890837Z",
     "shell.execute_reply.started": "2023-05-28T03:45:57.850436Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##slice tensor function in keras\n",
    "def crop(dimension, start, end):\n",
    "    # Crops (or slices) a Tensor on a given dimension from start to end\n",
    "    # example : to crop tensor x[:, :, 5:10]\n",
    "    # call slice(2, 5, 10) as you want to crop on the second dimension\n",
    "    def func(x):\n",
    "        if dimension == 0:\n",
    "            return x[start: end]\n",
    "        if dimension == 1:\n",
    "            return x[:, start: end]\n",
    "        if dimension == 2:\n",
    "            return x[:, :, start: end]\n",
    "        if dimension == 3:\n",
    "            return x[:, :, :, start: end]\n",
    "        if dimension == 4:\n",
    "            return x[:, :, :, :, start: end]\n",
    "\n",
    "    return Lambda(func)\n",
    "\n",
    "\n",
    "def myFunc(x):\n",
    "    if \"empety\" in x:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for dataset\n",
    "    Every dataset is lower cased except\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"\\\\\", \"\", string)\n",
    "    string = re.sub(r\"\\'\", \"\", string)\n",
    "    string = re.sub(r\"\\\"\", \"\", string)\n",
    "    string = string.strip().lower()\n",
    "    word_tokens = word_tokenize(string)\n",
    "    filtered_words = [word for word in word_tokens if word not in stopwords.words('english')]\n",
    "    return filtered_words\n",
    "\n",
    "\n",
    "def find_str(s, char):\n",
    "    index = 0\n",
    "\n",
    "    if char in s:\n",
    "        c = char[0]\n",
    "        for ch in s:\n",
    "            if ch == c:\n",
    "                if s[index:index + len(char)] == char:\n",
    "                    return index\n",
    "\n",
    "            index += 1\n",
    "\n",
    "\n",
    "class AttLayer(Layer):\n",
    "    def __init__(self, attention_dim):\n",
    "        self.init = initializers.get('normal')\n",
    "        self.supports_masking = True\n",
    "        self.attention_dim = attention_dim\n",
    "        super(AttLayer, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        self.W = K.variable(self.init((input_shape[-1], self.attention_dim)))\n",
    "        self.b = K.variable(self.init((self.attention_dim,)))\n",
    "        self.u = K.variable(self.init((self.attention_dim, 1)))\n",
    "        self.trainable_weightss = [self.W, self.b, self.u]\n",
    "        super(AttLayer, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return mask\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        # size of x :[batch_size, sel_len, attention_dim]\n",
    "        # size of u :[batch_size, attention_dim]\n",
    "        # uit = tanh(xW+b)\n",
    "        uit = K.tanh(K.bias_add(K.dot(x, self.W), self.b))\n",
    "        ait = K.dot(uit, self.u)\n",
    "        ait = K.squeeze(ait, -1)\n",
    "\n",
    "        ait = K.exp(ait)\n",
    "\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            ait *= K.cast(mask, K.floatx())\n",
    "        ait /= K.cast(K.sum(ait, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "        ait = K.expand_dims(ait)\n",
    "        weighted_input = x * ait\n",
    "        output = K.sum(weighted_input, axis=1)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])\n",
    "\n",
    "    \n",
    "class MultiHeadSelfAttention(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads=8):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        if embed_dim % num_heads != 0:\n",
    "            raise ValueError(\n",
    "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
    "            )\n",
    "        self.projection_dim = embed_dim // num_heads\n",
    "        self.query_dense = layers.Dense(embed_dim)\n",
    "        self.key_dense = layers.Dense(embed_dim)\n",
    "        self.value_dense = layers.Dense(embed_dim)\n",
    "        self.combine_heads = layers.Dense(embed_dim)\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        query = self.separate_heads(\n",
    "            query, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        key = self.separate_heads(\n",
    "            key, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        value = self.separate_heads(\n",
    "            value, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        attention, weights = self.attention(query, key, value)\n",
    "        attention = tf.transpose(\n",
    "            attention, perm=[0, 2, 1, 3]\n",
    "        )  # (batch_size, seq_len, num_heads, projection_dim)\n",
    "        concat_attention = tf.reshape(\n",
    "            attention, (batch_size, -1, self.embed_dim)\n",
    "        )  # (batch_size, seq_len, embed_dim)\n",
    "        output = self.combine_heads(\n",
    "            concat_attention\n",
    "        )  # (batch_size, seq_len, embed_dim)\n",
    "        return output\n",
    "\n",
    "\n",
    "'''Transformer的Encoder部分'''\n",
    "\n",
    "\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim), ]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "\n",
    "'''Transformer输入的编码层'''\n",
    "\n",
    "\n",
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a3a960f-cae4-4327-8b4b-ad2f3afe8c89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T03:45:58.899493Z",
     "iopub.status.busy": "2023-05-28T03:45:58.899032Z",
     "iopub.status.idle": "2023-05-28T03:46:16.233992Z",
     "shell.execute_reply": "2023-05-28T03:46:16.233514Z",
     "shell.execute_reply.started": "2023-05-28T03:45:58.899459Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 8009 unique tokens.\n",
      "Shape of data tensor: (2121, 192, 21)\n",
      "Shape of label tensor: (2121, 2)\n"
     ]
    }
   ],
   "source": [
    "with open('instagram.pickle', 'rb') as handle:\n",
    "    dictionary = pickle.load(handle)\n",
    "texts = dictionary['text']\n",
    "texts = texts.fillna(\"\")\n",
    "# texts=[text.encode('ascii') for text in texts]\n",
    "#print(texts)\n",
    "comments = dictionary['comments']\n",
    "#print(comments)\n",
    "timeInfo = dictionary['time']\n",
    "#print(timeInfo)\n",
    "postInfo = dictionary['post']\n",
    "#print(postInfo)\n",
    "\n",
    "#print(postInfo)\n",
    "labels = dictionary['labels']\n",
    "#print(labels)\n",
    "b = np.zeros([len(timeInfo), len(max(timeInfo, key=lambda x: len(x)))])\n",
    "for i, j in enumerate(timeInfo):\n",
    "    b[i][0:len(j)] = j\n",
    "timeInfo = b\n",
    "#print(b)\n",
    "time_size = len(np.unique(timeInfo))\n",
    "MAX_SENTS = len(timeInfo[0])  ####number of sentences\n",
    "\n",
    "c = np.zeros([len(postInfo), len(max(postInfo, key=lambda x: len(x)))])\n",
    "for i, j in enumerate(postInfo):\n",
    "    c[i][0:len(j)] = j\n",
    "median_value = np.median(c)\n",
    "c = np.where(c > 10000000,median_value , c)\n",
    "postInfo = c\n",
    "#print(postInfo)\n",
    "post_size = len(np.unique(postInfo))\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "#print(MAX_SENTS)\n",
    "data = np.zeros((len(texts), MAX_SENTS, MAX_SENT_LENGTH+1), dtype='int32')\n",
    "#print(tokenizer.word_index['club'])\n",
    "\n",
    "for i, sentences in enumerate(comments):\n",
    "    for j, sent in enumerate(sentences):\n",
    "        if j < MAX_SENTS:\n",
    "            wordTokens = text_to_word_sequence(sent)\n",
    "            k = 0\n",
    "            for word in wordTokens:\n",
    "                #print(type(wordTokens[0]))\n",
    "                #print(\"'{}'\".format(word))\n",
    "                if k < MAX_SENT_LENGTH and word in tokenizer.word_index:\n",
    "                    data[i, j, k] = tokenizer.word_index[word]\n",
    "                    k = k + 1\n",
    "#print(data)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Total %s unique tokens.' % len(word_index))\n",
    "single_label = np.asarray(labels)\n",
    "labels = to_categorical(np.asarray(labels))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "###standardize\n",
    "transfer = StandardScaler()\n",
    "timeInfo = transfer.fit_transform(timeInfo)\n",
    "postInfo = transfer.fit_transform(postInfo)\n",
    "HAN_pre = []\n",
    "HAN_reca = []\n",
    "HAN_f1 = []\n",
    "HAN_AUC = []\n",
    "HAN_TIME = []\n",
    "embeddings_index = Word2Vec.load_word2vec_format(\"word2vec_twitter_model.bin\", binary=True, )  #\n",
    "\n",
    "# print('Total %s word vectors.' % len(embeddings_index))\n",
    "embedding_matrix = np.random.random((len(word_index) + 1, POST_DIM))\n",
    "outword_dic = dict()\n",
    "for word, i in word_index.items():\n",
    "    if word in embeddings_index.vocab:\n",
    "        embedding_vector = embeddings_index[word]\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        new_vector = np.random.rand(POST_DIM, )\n",
    "        outword_dic.setdefault(word, new_vector)\n",
    "        embedding_matrix[i] = outword_dic[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "023cf799-fe17-4d2e-bb33-f32a0c02d3b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T03:53:46.695241Z",
     "iopub.status.busy": "2023-05-28T03:53:46.695007Z",
     "iopub.status.idle": "2023-05-28T03:54:44.159831Z",
     "shell.execute_reply": "2023-05-28T03:54:44.159529Z",
     "shell.execute_reply.started": "2023-05-28T03:53:46.695233Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2121, 192, 1)\n",
      "Number of positive and negative posts in training and test set\n",
      "[1170.  527.]\n",
      "[292. 132.]\n",
      "model fitting - Hierachical attention network for cyberbullying detection\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 113s 4s/step - loss: 0.7334 - activation_2_loss: 0.7333 - lambda_3_loss: 1.8300\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.7128 - activation_2_loss: 0.7128 - lambda_3_loss: 1.7883\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.7013 - activation_2_loss: 0.7012 - lambda_3_loss: 1.7857\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.6916 - activation_2_loss: 0.6916 - lambda_3_loss: 1.7909\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6794 - activation_2_loss: 0.6794 - lambda_3_loss: 1.7841\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 113s 4s/step - loss: 0.6707 - activation_2_loss: 0.6706 - lambda_3_loss: 1.7840\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6713 - activation_2_loss: 0.6713 - lambda_3_loss: 1.7778\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6560 - activation_2_loss: 0.6560 - lambda_3_loss: 1.7814\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.6620 - activation_2_loss: 0.6620 - lambda_3_loss: 1.7730\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.6511 - activation_2_loss: 0.6511 - lambda_3_loss: 1.7715\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.6497 - activation_2_loss: 0.6497 - lambda_3_loss: 1.7734\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.6476 - activation_2_loss: 0.6476 - lambda_3_loss: 1.7741\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6447 - activation_2_loss: 0.6447 - lambda_3_loss: 1.7685\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6462 - activation_2_loss: 0.6462 - lambda_3_loss: 1.7739\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6380 - activation_2_loss: 0.6380 - lambda_3_loss: 1.7711\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6407 - activation_2_loss: 0.6406 - lambda_3_loss: 1.7683\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.6364 - activation_2_loss: 0.6364 - lambda_3_loss: 1.7705\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6337 - activation_2_loss: 0.6337 - lambda_3_loss: 1.7754\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6320 - activation_2_loss: 0.6320 - lambda_3_loss: 1.7730\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6283 - activation_2_loss: 0.6282 - lambda_3_loss: 1.7711\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6273 - activation_2_loss: 0.6273 - lambda_3_loss: 1.7664\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6308 - activation_2_loss: 0.6308 - lambda_3_loss: 1.7683\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6327 - activation_2_loss: 0.6327 - lambda_3_loss: 1.7695\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6282 - activation_2_loss: 0.6282 - lambda_3_loss: 1.7731\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6229 - activation_2_loss: 0.6229 - lambda_3_loss: 1.7699\n",
      "14/14 [==============================] - 10s 655ms/step\n",
      "cpu_time:\n",
      "32127.421875\n",
      "f1:\n",
      "(array([0.75722543, 0.61538462]), array([0.89726027, 0.36363636]), array([0.82131661, 0.45714286]), array([292, 132], dtype=int64))\n",
      "auc:\n",
      "0.6304483188044833\n",
      "(2121, 192, 1)\n",
      "Number of positive and negative posts in training and test set\n",
      "[1166.  531.]\n",
      "[296. 128.]\n",
      "model fitting - Hierachical attention network for cyberbullying detection\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 113s 4s/step - loss: 0.7399 - activation_5_loss: 0.7398 - lambda_7_loss: 1.8564\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.7096 - activation_5_loss: 0.7096 - lambda_7_loss: 1.8301\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6964 - activation_5_loss: 0.6964 - lambda_7_loss: 1.7990\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6869 - activation_5_loss: 0.6868 - lambda_7_loss: 1.7969\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6700 - activation_5_loss: 0.6700 - lambda_7_loss: 1.7858\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6692 - activation_5_loss: 0.6692 - lambda_7_loss: 1.7820\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6569 - activation_5_loss: 0.6569 - lambda_7_loss: 1.7715\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6558 - activation_5_loss: 0.6557 - lambda_7_loss: 1.7657\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6542 - activation_5_loss: 0.6542 - lambda_7_loss: 1.7681\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6518 - activation_5_loss: 0.6517 - lambda_7_loss: 1.7656\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6474 - activation_5_loss: 0.6474 - lambda_7_loss: 1.7520\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6449 - activation_5_loss: 0.6448 - lambda_7_loss: 1.7511\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6445 - activation_5_loss: 0.6445 - lambda_7_loss: 1.7525\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6405 - activation_5_loss: 0.6405 - lambda_7_loss: 1.7546\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.6452 - activation_5_loss: 0.6452 - lambda_7_loss: 1.7544\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6363 - activation_5_loss: 0.6363 - lambda_7_loss: 1.7476\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6335 - activation_5_loss: 0.6335 - lambda_7_loss: 1.7470\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.6363 - activation_5_loss: 0.6363 - lambda_7_loss: 1.7463\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6331 - activation_5_loss: 0.6330 - lambda_7_loss: 1.7438\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6289 - activation_5_loss: 0.6289 - lambda_7_loss: 1.7418\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6327 - activation_5_loss: 0.6327 - lambda_7_loss: 1.7393\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6277 - activation_5_loss: 0.6276 - lambda_7_loss: 1.7436\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6334 - activation_5_loss: 0.6334 - lambda_7_loss: 1.7420\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6289 - activation_5_loss: 0.6288 - lambda_7_loss: 1.7422\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.6311 - activation_5_loss: 0.6311 - lambda_7_loss: 1.7418\n",
      "14/14 [==============================] - 10s 666ms/step\n",
      "cpu_time:\n",
      "32406.140625\n",
      "f1:\n",
      "(array([0.7641791, 0.5505618]), array([0.86486486, 0.3828125 ]), array([0.81141046, 0.4516129 ]), array([296, 128], dtype=int64))\n",
      "auc:\n",
      "0.6238386824324325\n",
      "(2121, 192, 1)\n",
      "Number of positive and negative posts in training and test set\n",
      "[1155.  542.]\n",
      "[307. 117.]\n",
      "model fitting - Hierachical attention network for cyberbullying detection\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 120s 4s/step - loss: 0.7939 - activation_8_loss: 0.7938 - lambda_11_loss: 2.2051\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 115s 4s/step - loss: 0.7774 - activation_8_loss: 0.7774 - lambda_11_loss: 2.2392\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 116s 4s/step - loss: 0.7669 - activation_8_loss: 0.7669 - lambda_11_loss: 2.2517\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 115s 4s/step - loss: 0.7631 - activation_8_loss: 0.7630 - lambda_11_loss: 2.2655\n",
      "Epoch 5/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 115s 4s/step - loss: 0.7539 - activation_8_loss: 0.7538 - lambda_11_loss: 2.2681\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 115s 4s/step - loss: 0.7458 - activation_8_loss: 0.7457 - lambda_11_loss: 2.2777\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 114s 4s/step - loss: 0.7378 - activation_8_loss: 0.7378 - lambda_11_loss: 2.2765\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 115s 4s/step - loss: 0.7383 - activation_8_loss: 0.7383 - lambda_11_loss: 2.2778\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 115s 4s/step - loss: 0.7293 - activation_8_loss: 0.7292 - lambda_11_loss: 2.2740\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 115s 4s/step - loss: 0.7285 - activation_8_loss: 0.7285 - lambda_11_loss: 2.2775\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 114s 4s/step - loss: 0.7213 - activation_8_loss: 0.7213 - lambda_11_loss: 2.2733\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 114s 4s/step - loss: 0.7196 - activation_8_loss: 0.7195 - lambda_11_loss: 2.2705\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 114s 4s/step - loss: 0.7135 - activation_8_loss: 0.7134 - lambda_11_loss: 2.2697\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 114s 4s/step - loss: 0.7124 - activation_8_loss: 0.7123 - lambda_11_loss: 2.2661\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 115s 4s/step - loss: 0.7039 - activation_8_loss: 0.7039 - lambda_11_loss: 2.2641\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 114s 4s/step - loss: 0.7016 - activation_8_loss: 0.7015 - lambda_11_loss: 2.2624\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 114s 4s/step - loss: 0.6898 - activation_8_loss: 0.6898 - lambda_11_loss: 2.2656\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 114s 4s/step - loss: 0.6960 - activation_8_loss: 0.6959 - lambda_11_loss: 2.2546\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 114s 4s/step - loss: 0.6871 - activation_8_loss: 0.6870 - lambda_11_loss: 2.2582\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 114s 4s/step - loss: 0.6840 - activation_8_loss: 0.6839 - lambda_11_loss: 2.2572\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 117s 4s/step - loss: 0.6801 - activation_8_loss: 0.6800 - lambda_11_loss: 2.2532\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 116s 4s/step - loss: 0.6842 - activation_8_loss: 0.6841 - lambda_11_loss: 2.2522\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 117s 4s/step - loss: 0.6784 - activation_8_loss: 0.6783 - lambda_11_loss: 2.2498\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 115s 4s/step - loss: 0.6772 - activation_8_loss: 0.6772 - lambda_11_loss: 2.2504\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 115s 4s/step - loss: 0.6708 - activation_8_loss: 0.6708 - lambda_11_loss: 2.2468\n",
      "14/14 [==============================] - 10s 678ms/step\n",
      "cpu_time:\n",
      "33965.90625\n",
      "f1:\n",
      "(array([0.76231884, 0.44303797]), array([0.85667752, 0.2991453 ]), array([0.80674847, 0.35714286]), array([307, 117], dtype=int64))\n",
      "auc:\n",
      "0.5779114117876333\n",
      "(2121, 192, 1)\n",
      "Number of positive and negative posts in training and test set\n",
      "[1175.  522.]\n",
      "[287. 137.]\n",
      "model fitting - Hierachical attention network for cyberbullying detection\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 116s 4s/step - loss: 0.7822 - activation_11_loss: 0.7821 - lambda_15_loss: 1.9114\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.7796 - activation_11_loss: 0.7796 - lambda_15_loss: 1.8811\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 113s 4s/step - loss: 0.7689 - activation_11_loss: 0.7688 - lambda_15_loss: 1.8577\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 115s 4s/step - loss: 0.7520 - activation_11_loss: 0.7520 - lambda_15_loss: 1.8295\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 113s 4s/step - loss: 0.7525 - activation_11_loss: 0.7525 - lambda_15_loss: 1.8138\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.7471 - activation_11_loss: 0.7470 - lambda_15_loss: 1.8062\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.7433 - activation_11_loss: 0.7433 - lambda_15_loss: 1.8046\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.7442 - activation_11_loss: 0.7442 - lambda_15_loss: 1.7992\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.7383 - activation_11_loss: 0.7383 - lambda_15_loss: 1.7910\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.7398 - activation_11_loss: 0.7398 - lambda_15_loss: 1.7901\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 113s 4s/step - loss: 0.7335 - activation_11_loss: 0.7335 - lambda_15_loss: 1.7901\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.7330 - activation_11_loss: 0.7329 - lambda_15_loss: 1.7854\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.7287 - activation_11_loss: 0.7287 - lambda_15_loss: 1.7898\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.7288 - activation_11_loss: 0.7287 - lambda_15_loss: 1.7799\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 113s 4s/step - loss: 0.7318 - activation_11_loss: 0.7318 - lambda_15_loss: 1.7819\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 113s 4s/step - loss: 0.7282 - activation_11_loss: 0.7282 - lambda_15_loss: 1.7813\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 113s 4s/step - loss: 0.7279 - activation_11_loss: 0.7278 - lambda_15_loss: 1.7793\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 113s 4s/step - loss: 0.7267 - activation_11_loss: 0.7266 - lambda_15_loss: 1.7725\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.7266 - activation_11_loss: 0.7266 - lambda_15_loss: 1.7781\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.7247 - activation_11_loss: 0.7247 - lambda_15_loss: 1.7749\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.7271 - activation_11_loss: 0.7271 - lambda_15_loss: 1.7773\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.7210 - activation_11_loss: 0.7210 - lambda_15_loss: 1.7697\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.7209 - activation_11_loss: 0.7209 - lambda_15_loss: 1.7717\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.7259 - activation_11_loss: 0.7259 - lambda_15_loss: 1.7735\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.7209 - activation_11_loss: 0.7209 - lambda_15_loss: 1.7683\n",
      "14/14 [==============================] - 10s 670ms/step\n",
      "cpu_time:\n",
      "32804.515625\n",
      "f1:\n",
      "(array([0.7254902 , 0.33850932]), array([0.25783972, 0.79562044]), array([0.38046272, 0.47494553]), array([287, 137], dtype=int64))\n",
      "auc:\n",
      "0.5267300796052798\n",
      "(2121, 192, 1)\n",
      "Number of positive and negative posts in training and test set\n",
      "[1178.  519.]\n",
      "[284. 140.]\n",
      "model fitting - Hierachical attention network for cyberbullying detection\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 115s 4s/step - loss: 0.7594 - activation_14_loss: 0.7594 - lambda_19_loss: 2.0013\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.7291 - activation_14_loss: 0.7290 - lambda_19_loss: 2.0009\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.7126 - activation_14_loss: 0.7126 - lambda_19_loss: 1.9913\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.7043 - activation_14_loss: 0.7043 - lambda_19_loss: 1.9874\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.6911 - activation_14_loss: 0.6911 - lambda_19_loss: 1.9877\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.6779 - activation_14_loss: 0.6779 - lambda_19_loss: 1.9756\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.6748 - activation_14_loss: 0.6748 - lambda_19_loss: 1.9678\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.6671 - activation_14_loss: 0.6671 - lambda_19_loss: 1.9594\n",
      "Epoch 9/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 112s 4s/step - loss: 0.6633 - activation_14_loss: 0.6632 - lambda_19_loss: 1.9480\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.6636 - activation_14_loss: 0.6636 - lambda_19_loss: 1.9398\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.6547 - activation_14_loss: 0.6546 - lambda_19_loss: 1.9309\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.6533 - activation_14_loss: 0.6532 - lambda_19_loss: 1.9213\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.6521 - activation_14_loss: 0.6520 - lambda_19_loss: 1.9158\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.6482 - activation_14_loss: 0.6481 - lambda_19_loss: 1.9172\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.6491 - activation_14_loss: 0.6490 - lambda_19_loss: 1.9147\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.6433 - activation_14_loss: 0.6432 - lambda_19_loss: 1.9050\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 114s 4s/step - loss: 0.6486 - activation_14_loss: 0.6485 - lambda_19_loss: 1.8964\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 117s 4s/step - loss: 0.6407 - activation_14_loss: 0.6407 - lambda_19_loss: 1.8940\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 114s 4s/step - loss: 0.6415 - activation_14_loss: 0.6415 - lambda_19_loss: 1.8931\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.6422 - activation_14_loss: 0.6421 - lambda_19_loss: 1.8827\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6379 - activation_14_loss: 0.6379 - lambda_19_loss: 1.8817\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.6388 - activation_14_loss: 0.6387 - lambda_19_loss: 1.8814\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6402 - activation_14_loss: 0.6402 - lambda_19_loss: 1.8774\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6391 - activation_14_loss: 0.6391 - lambda_19_loss: 1.8725\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.6349 - activation_14_loss: 0.6349 - lambda_19_loss: 1.8694\n",
      "14/14 [==============================] - 10s 672ms/step\n",
      "cpu_time:\n",
      "32779.296875\n",
      "f1:\n",
      "(array([0.74635569, 0.65432099]), array([0.90140845, 0.37857143]), array([0.81658692, 0.47963801]), array([284, 140], dtype=int64))\n",
      "auc:\n",
      "0.639989939637827\n",
      "(2121, 192, 1)\n",
      "Number of positive and negative posts in training and test set\n",
      "[1162.  535.]\n",
      "[300. 124.]\n",
      "model fitting - Hierachical attention network for cyberbullying detection\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 114s 4s/step - loss: 0.7503 - activation_17_loss: 0.7502 - lambda_23_loss: 1.9679\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.7292 - activation_17_loss: 0.7291 - lambda_23_loss: 1.8480\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 121s 4s/step - loss: 0.7274 - activation_17_loss: 0.7274 - lambda_23_loss: 1.8410\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 122s 5s/step - loss: 0.7232 - activation_17_loss: 0.7231 - lambda_23_loss: 1.8456\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 121s 4s/step - loss: 0.7225 - activation_17_loss: 0.7225 - lambda_23_loss: 1.8389\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 116s 4s/step - loss: 0.7183 - activation_17_loss: 0.7183 - lambda_23_loss: 1.8301\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.7146 - activation_17_loss: 0.7145 - lambda_23_loss: 1.8435\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.7180 - activation_17_loss: 0.7180 - lambda_23_loss: 1.8339\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.7145 - activation_17_loss: 0.7145 - lambda_23_loss: 1.8276\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.7144 - activation_17_loss: 0.7144 - lambda_23_loss: 1.8341\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.7110 - activation_17_loss: 0.7110 - lambda_23_loss: 1.8368\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.7083 - activation_17_loss: 0.7083 - lambda_23_loss: 1.8418\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.7115 - activation_17_loss: 0.7115 - lambda_23_loss: 1.8338\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 113s 4s/step - loss: 0.7090 - activation_17_loss: 0.7090 - lambda_23_loss: 1.8408\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 116s 4s/step - loss: 0.7049 - activation_17_loss: 0.7048 - lambda_23_loss: 1.8290\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 120s 4s/step - loss: 0.7004 - activation_17_loss: 0.7004 - lambda_23_loss: 1.8348\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 120s 4s/step - loss: 0.7084 - activation_17_loss: 0.7083 - lambda_23_loss: 1.8421\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 120s 4s/step - loss: 0.7016 - activation_17_loss: 0.7015 - lambda_23_loss: 1.8430\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 120s 4s/step - loss: 0.6993 - activation_17_loss: 0.6993 - lambda_23_loss: 1.8314\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 120s 4s/step - loss: 0.6995 - activation_17_loss: 0.6994 - lambda_23_loss: 1.8442\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 117s 4s/step - loss: 0.6993 - activation_17_loss: 0.6993 - lambda_23_loss: 1.8327\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6889 - activation_17_loss: 0.6889 - lambda_23_loss: 1.8471\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6895 - activation_17_loss: 0.6895 - lambda_23_loss: 1.8428\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6891 - activation_17_loss: 0.6891 - lambda_23_loss: 1.8460\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6859 - activation_17_loss: 0.6858 - lambda_23_loss: 1.8492\n",
      "14/14 [==============================] - 10s 661ms/step\n",
      "cpu_time:\n",
      "32287.875\n",
      "f1:\n",
      "(array([0.75354108, 0.52112676]), array([0.88666667, 0.2983871 ]), array([0.81470138, 0.37948718]), array([300, 124], dtype=int64))\n",
      "auc:\n",
      "0.5925268817204301\n",
      "(2121, 192, 1)\n",
      "Number of positive and negative posts in training and test set\n",
      "[1177.  520.]\n",
      "[285. 139.]\n",
      "model fitting - Hierachical attention network for cyberbullying detection\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 113s 4s/step - loss: 0.7825 - activation_20_loss: 0.7825 - lambda_27_loss: 1.7653\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.7637 - activation_20_loss: 0.7637 - lambda_27_loss: 1.7408\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.7440 - activation_20_loss: 0.7440 - lambda_27_loss: 1.7089\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.7161 - activation_20_loss: 0.7161 - lambda_27_loss: 1.6940\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6993 - activation_20_loss: 0.6993 - lambda_27_loss: 1.6912\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6897 - activation_20_loss: 0.6897 - lambda_27_loss: 1.6867\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6814 - activation_20_loss: 0.6814 - lambda_27_loss: 1.6939\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6717 - activation_20_loss: 0.6717 - lambda_27_loss: 1.6951\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6655 - activation_20_loss: 0.6655 - lambda_27_loss: 1.6932\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6603 - activation_20_loss: 0.6602 - lambda_27_loss: 1.6962\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6543 - activation_20_loss: 0.6543 - lambda_27_loss: 1.6912\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.6546 - activation_20_loss: 0.6546 - lambda_27_loss: 1.6877\n",
      "Epoch 13/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 110s 4s/step - loss: 0.6532 - activation_20_loss: 0.6532 - lambda_27_loss: 1.6891\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6513 - activation_20_loss: 0.6513 - lambda_27_loss: 1.6892\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6475 - activation_20_loss: 0.6475 - lambda_27_loss: 1.6936\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6490 - activation_20_loss: 0.6490 - lambda_27_loss: 1.6867\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6451 - activation_20_loss: 0.6450 - lambda_27_loss: 1.6907\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6420 - activation_20_loss: 0.6420 - lambda_27_loss: 1.6844\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6457 - activation_20_loss: 0.6457 - lambda_27_loss: 1.6865\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6449 - activation_20_loss: 0.6448 - lambda_27_loss: 1.6929\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6398 - activation_20_loss: 0.6398 - lambda_27_loss: 1.6817\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6381 - activation_20_loss: 0.6380 - lambda_27_loss: 1.6876\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6343 - activation_20_loss: 0.6343 - lambda_27_loss: 1.6888\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6355 - activation_20_loss: 0.6354 - lambda_27_loss: 1.6881\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6305 - activation_20_loss: 0.6305 - lambda_27_loss: 1.6894\n",
      "14/14 [==============================] - 10s 665ms/step\n",
      "cpu_time:\n",
      "32533.640625\n",
      "f1:\n",
      "(array([0.75949367, 0.58333333]), array([0.84210526, 0.45323741]), array([0.79866889, 0.51012146]), array([285, 139], dtype=int64))\n",
      "auc:\n",
      "0.6476713366149185\n",
      "(2121, 192, 1)\n",
      "Number of positive and negative posts in training and test set\n",
      "[1164.  533.]\n",
      "[298. 126.]\n",
      "model fitting - Hierachical attention network for cyberbullying detection\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 114s 4s/step - loss: 0.8364 - activation_23_loss: 0.8363 - lambda_31_loss: 1.9467\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.8226 - activation_23_loss: 0.8225 - lambda_31_loss: 1.9468\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 114s 4s/step - loss: 0.7941 - activation_23_loss: 0.7941 - lambda_31_loss: 1.9164\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.7524 - activation_23_loss: 0.7523 - lambda_31_loss: 1.8955\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.7374 - activation_23_loss: 0.7374 - lambda_31_loss: 1.8812\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.7206 - activation_23_loss: 0.7206 - lambda_31_loss: 1.8750\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.7089 - activation_23_loss: 0.7089 - lambda_31_loss: 1.8696\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6914 - activation_23_loss: 0.6913 - lambda_31_loss: 1.8663\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6835 - activation_23_loss: 0.6834 - lambda_31_loss: 1.8616\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6743 - activation_23_loss: 0.6742 - lambda_31_loss: 1.8586\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6693 - activation_23_loss: 0.6692 - lambda_31_loss: 1.8574\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6678 - activation_23_loss: 0.6678 - lambda_31_loss: 1.8592\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6696 - activation_23_loss: 0.6696 - lambda_31_loss: 1.8586\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6614 - activation_23_loss: 0.6613 - lambda_31_loss: 1.8546\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6610 - activation_23_loss: 0.6610 - lambda_31_loss: 1.8577\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6590 - activation_23_loss: 0.6589 - lambda_31_loss: 1.8553\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6556 - activation_23_loss: 0.6555 - lambda_31_loss: 1.8599\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6533 - activation_23_loss: 0.6533 - lambda_31_loss: 1.8561\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6492 - activation_23_loss: 0.6492 - lambda_31_loss: 1.8529\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6536 - activation_23_loss: 0.6536 - lambda_31_loss: 1.8557\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6491 - activation_23_loss: 0.6490 - lambda_31_loss: 1.8515\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6470 - activation_23_loss: 0.6469 - lambda_31_loss: 1.8578\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6490 - activation_23_loss: 0.6490 - lambda_31_loss: 1.8519\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6412 - activation_23_loss: 0.6411 - lambda_31_loss: 1.8521\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6450 - activation_23_loss: 0.6449 - lambda_31_loss: 1.8523\n",
      "14/14 [==============================] - 10s 666ms/step\n",
      "cpu_time:\n",
      "32736.109375\n",
      "f1:\n",
      "(array([0.76315789, 0.45      ]), array([0.77852349, 0.42857143]), array([0.77076412, 0.43902439]), array([298, 126], dtype=int64))\n",
      "auc:\n",
      "0.6035474592521572\n",
      "(2121, 192, 1)\n",
      "Number of positive and negative posts in training and test set\n",
      "[1173.  524.]\n",
      "[289. 135.]\n",
      "model fitting - Hierachical attention network for cyberbullying detection\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 113s 4s/step - loss: 0.7161 - activation_26_loss: 0.7161 - lambda_35_loss: 2.0570\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.7006 - activation_26_loss: 0.7006 - lambda_35_loss: 2.0763\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.7007 - activation_26_loss: 0.7006 - lambda_35_loss: 2.0737\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6930 - activation_26_loss: 0.6930 - lambda_35_loss: 2.0805\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6904 - activation_26_loss: 0.6903 - lambda_35_loss: 2.0829\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6890 - activation_26_loss: 0.6889 - lambda_35_loss: 2.0789\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6744 - activation_26_loss: 0.6744 - lambda_35_loss: 2.0810\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6756 - activation_26_loss: 0.6756 - lambda_35_loss: 2.0790\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6654 - activation_26_loss: 0.6654 - lambda_35_loss: 2.0760\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6705 - activation_26_loss: 0.6704 - lambda_35_loss: 2.0728\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6619 - activation_26_loss: 0.6619 - lambda_35_loss: 2.0752\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6596 - activation_26_loss: 0.6596 - lambda_35_loss: 2.0741\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6558 - activation_26_loss: 0.6558 - lambda_35_loss: 2.0674\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6505 - activation_26_loss: 0.6505 - lambda_35_loss: 2.0689\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6469 - activation_26_loss: 0.6468 - lambda_35_loss: 2.0688\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6448 - activation_26_loss: 0.6448 - lambda_35_loss: 2.0665\n",
      "Epoch 17/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 110s 4s/step - loss: 0.6513 - activation_26_loss: 0.6512 - lambda_35_loss: 2.0674\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6397 - activation_26_loss: 0.6397 - lambda_35_loss: 2.0608\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6418 - activation_26_loss: 0.6417 - lambda_35_loss: 2.0567\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6402 - activation_26_loss: 0.6401 - lambda_35_loss: 2.0621\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6354 - activation_26_loss: 0.6353 - lambda_35_loss: 2.0589\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6359 - activation_26_loss: 0.6359 - lambda_35_loss: 2.0573\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6318 - activation_26_loss: 0.6318 - lambda_35_loss: 2.0546\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6329 - activation_26_loss: 0.6329 - lambda_35_loss: 2.0584\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 110s 4s/step - loss: 0.6343 - activation_26_loss: 0.6343 - lambda_35_loss: 2.0532\n",
      "14/14 [==============================] - 10s 658ms/step\n",
      "cpu_time:\n",
      "32467.546875\n",
      "f1:\n",
      "(array([0.76282051, 0.54464286]), array([0.82352941, 0.45185185]), array([0.79201331, 0.49392713]), array([289, 135], dtype=int64))\n",
      "auc:\n",
      "0.6376906318082788\n",
      "(2121, 192, 1)\n",
      "Number of positive and negative posts in training and test set\n",
      "[1170.  527.]\n",
      "[292. 132.]\n",
      "model fitting - Hierachical attention network for cyberbullying detection\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 114s 4s/step - loss: 0.7043 - activation_29_loss: 0.7042 - lambda_39_loss: 2.0769\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6901 - activation_29_loss: 0.6901 - lambda_39_loss: 2.0683\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6850 - activation_29_loss: 0.6850 - lambda_39_loss: 2.0725\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6805 - activation_29_loss: 0.6804 - lambda_39_loss: 2.0681\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6768 - activation_29_loss: 0.6768 - lambda_39_loss: 2.0632\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6702 - activation_29_loss: 0.6702 - lambda_39_loss: 2.0543\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6658 - activation_29_loss: 0.6658 - lambda_39_loss: 2.0492\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6648 - activation_29_loss: 0.6648 - lambda_39_loss: 2.0471\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6577 - activation_29_loss: 0.6576 - lambda_39_loss: 2.0372\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 114s 4s/step - loss: 0.6602 - activation_29_loss: 0.6601 - lambda_39_loss: 2.0396\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 114s 4s/step - loss: 0.6603 - activation_29_loss: 0.6602 - lambda_39_loss: 2.0375\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 125s 5s/step - loss: 0.6471 - activation_29_loss: 0.6471 - lambda_39_loss: 2.0295\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 156s 6s/step - loss: 0.6492 - activation_29_loss: 0.6492 - lambda_39_loss: 2.0302\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 156s 6s/step - loss: 0.6446 - activation_29_loss: 0.6445 - lambda_39_loss: 2.0279\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 155s 6s/step - loss: 0.6414 - activation_29_loss: 0.6414 - lambda_39_loss: 2.0225\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 152s 6s/step - loss: 0.6428 - activation_29_loss: 0.6427 - lambda_39_loss: 2.0260\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 151s 6s/step - loss: 0.6377 - activation_29_loss: 0.6377 - lambda_39_loss: 2.0190\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 124s 5s/step - loss: 0.6453 - activation_29_loss: 0.6452 - lambda_39_loss: 2.0131\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 108s 4s/step - loss: 0.6420 - activation_29_loss: 0.6420 - lambda_39_loss: 2.0165\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6385 - activation_29_loss: 0.6384 - lambda_39_loss: 2.0116\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 112s 4s/step - loss: 0.6353 - activation_29_loss: 0.6353 - lambda_39_loss: 2.0106\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6349 - activation_29_loss: 0.6348 - lambda_39_loss: 2.0093\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6281 - activation_29_loss: 0.6281 - lambda_39_loss: 2.0059\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6283 - activation_29_loss: 0.6282 - lambda_39_loss: 2.0010\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 111s 4s/step - loss: 0.6279 - activation_29_loss: 0.6279 - lambda_39_loss: 2.0016\n",
      "14/14 [==============================] - 10s 657ms/step\n",
      "cpu_time:\n",
      "34795.546875\n",
      "f1:\n",
      "(array([0.74695122, 0.51041667]), array([0.8390411 , 0.37121212]), array([0.79032258, 0.42982456]), array([292, 132], dtype=int64))\n",
      "auc:\n",
      "0.605126608551266\n",
      "[0.6304483188044833, 0.6238386824324325, 0.5779114117876333, 0.5267300796052798, 0.639989939637827, 0.5925268817204301, 0.6476713366149185, 0.6035474592521572, 0.6376906318082788, 0.605126608551266]\n",
      "[0.4571428571428572, 0.4516129032258065, 0.3571428571428571, 0.4749455337690632, 0.4796380090497738, 0.3794871794871795, 0.5101214574898786, 0.4390243902439024, 0.4939271255060728, 0.4298245614035088]\n",
      "[0.6153846153846154, 0.550561797752809, 0.4430379746835443, 0.3385093167701863, 0.654320987654321, 0.5211267605633803, 0.5833333333333334, 0.45, 0.5446428571428571, 0.5104166666666666]\n",
      "[0.36363636363636365, 0.3828125, 0.29914529914529914, 0.7956204379562044, 0.37857142857142856, 0.29838709677419356, 0.45323741007194246, 0.42857142857142855, 0.45185185185185184, 0.3712121212121212]\n",
      "[32127.421875, 32406.140625, 33965.90625, 32804.515625, 32779.296875, 32287.875, 32533.640625, 32736.109375, 32467.546875, 34795.546875]\n",
      "TIME 32890.4 794.7065553038861\n",
      "AUC 0.6085481350214705 0.034652724497139104\n",
      "f1 0.44728668744609 0.04598575173307764\n",
      "precision 0.5211334309951713 0.08748430843678963\n",
      "recall 0.42230459377908336 0.1346410960387974\n"
     ]
    }
   ],
   "source": [
    "for j in range(10):\n",
    "    start_time = process_time()\n",
    "    indices = np.arange(data.shape[0])\n",
    "    #print(indices)\n",
    "    np.random.shuffle(indices)\n",
    "    data1 = data[indices]\n",
    "    #print(data1.shape)\n",
    "    labels1 = labels[indices]\n",
    "    single_label1 = single_label[indices]\n",
    "    timeInfo1 = timeInfo[indices]\n",
    "    #print(timeInfo1.shape)\n",
    "    timeInfo1 = timeInfo1.reshape((2121, MAX_SENTS, 1))\n",
    "    print(timeInfo1.shape)\n",
    "    data1 = np.dstack((data1, timeInfo1))\n",
    "    postInfo1=postInfo[indices]\n",
    "    #print(postInfo1.shape)\n",
    "    nb_validation_samples = int(VALIDATION_SPLIT * data1.shape[0])\n",
    "    zeros = np.zeros(2121)\n",
    "    zeros = zeros.reshape((2121, 1, 1))\n",
    "\n",
    "    x_train = data1[:-nb_validation_samples]\n",
    "    m=crop(1, 0, MAX_SENT_LENGTH)(x_train)\n",
    "    # print(m)\n",
    "    y_train = labels1[:-nb_validation_samples]\n",
    "    #print(y_train.shape)\n",
    "    zeros_train = zeros[:-nb_validation_samples]\n",
    "    time_train = timeInfo1[:-nb_validation_samples]\n",
    "    post_train = postInfo1[:-nb_validation_samples]\n",
    "    median_value1 = np.median(post_train)\n",
    "    post_train = np.where(np.isnan(post_train), 0, post_train)\n",
    "    x_val = data1[-nb_validation_samples:]\n",
    "    y_val = labels1[-nb_validation_samples:]\n",
    "    zeros_test = zeros[-nb_validation_samples:]\n",
    "    time_test = timeInfo1[-nb_validation_samples:]\n",
    "    post_test = postInfo1[-nb_validation_samples:]\n",
    "    median_value2 = np.median(post_test)\n",
    "    post_test = np.where(np.isnan(post_test), 0, post_test)\n",
    "    y_single = single_label1[-nb_validation_samples:]\n",
    "\n",
    "    print('Number of positive and negative posts in training and test set')\n",
    "    print(y_train.sum(axis=0))\n",
    "    print(y_val.sum(axis=0))\n",
    "\n",
    "    # building Hierachical Attention network\n",
    "\n",
    "    embedding_layer = Embedding(len(word_index) + 1,\n",
    "                                POST_DIM,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=MAX_SENT_LENGTH,\n",
    "                                trainable=True,\n",
    "                                mask_zero=True)\n",
    "\n",
    "    all_input = Input(shape=(MAX_SENT_LENGTH + 2,))\n",
    "    sentence_input = crop(1, 0, MAX_SENT_LENGTH)(all_input)  ##slice\n",
    "    time_input = crop(1, MAX_SENT_LENGTH, MAX_SENT_LENGTH + 2)(all_input)  ##slice\n",
    "    embed_dim = 200  # Embedding size for each token\n",
    "    num_heads = 2  # Number of attention heads\n",
    "    ff_dim = 200  # Hidden layer size in feed forward network inside transformer\n",
    "    vocab_size = 20000\n",
    "    embedding_layer1 = TokenAndPositionEmbedding(MAX_SENT_LENGTH, vocab_size, embed_dim)\n",
    "    x = embedding_layer1(sentence_input)\n",
    "    transformer_block1 = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "    l_trans = transformer_block1(x)\n",
    "    l_att = GlobalAveragePooling1D()(l_trans)\n",
    "    l_att = Dense(200, activation='sigmoid')(l_att)  ####(?,200)\n",
    "    # time_embedding=Dense(TIME_DIM,activation='sigmoid')(time_input)\n",
    "    merged_output = Concatenate()([l_att, time_input])  ###text+time information\n",
    "    sentEncoder = Model(all_input, merged_output)\n",
    "\n",
    "    review_input = Input(shape=(MAX_SENTS, MAX_SENT_LENGTH+2))\n",
    "    review_encoder = TimeDistributed(sentEncoder)(review_input)\n",
    "    transformer_block2 = TransformerBlock(202, num_heads, ff_dim)\n",
    "    l_lstm_sent = transformer_block2(review_encoder)\n",
    "    # pred_time=Dense(1,activation='relu')(l_lstm_sent)\n",
    "    fully_sent = Dense(1, use_bias=False)(l_lstm_sent)\n",
    "    norm_fullysent = BatchNormalization()(fully_sent)\n",
    "    pred_time = Activation(activation='linear')(norm_fullysent)\n",
    "\n",
    "    zero_input = Input(shape=(1, 1))\n",
    "    shift_predtime = Concatenate(axis=1)([zero_input, pred_time])\n",
    "    shift_predtime = crop(1, 0, MAX_SENTS)(shift_predtime)\n",
    "    l_att_sent = GlobalAveragePooling1D()(l_lstm_sent)\n",
    "    l_att_sent = Dense(200, activation='sigmoid')(l_att_sent)\n",
    "\n",
    "    ###embed the #likes, shares\n",
    "    post_input = Input(shape=(4,))\n",
    "    #print(post_input)\n",
    "    # post_embedding = Dense(INFO_DIM, activation='sigmoid')(post_input)\n",
    "    fully_post = Dense(INFO_DIM, use_bias=False)(post_input)\n",
    "    norm_fullypost = BatchNormalization()(fully_post)\n",
    "    post_embedding = Activation(activation='relu')(norm_fullypost)\n",
    "    x = concatenate([l_att_sent,\n",
    "                     post_embedding])  ###merge the document level vectro with the additional embedded features such as #likes\n",
    "    fully_review = Dense(2, use_bias=False)(x)\n",
    "    norm_fullyreview = BatchNormalization()(fully_review)\n",
    "    preds = Activation(activation='softmax')(norm_fullyreview)\n",
    "\n",
    "    rmsprop = optimizers.Adam(learning_rate=0.001, decay=0.99)\n",
    "    model = Model(inputs=[review_input, post_input, zero_input], outputs=[preds, shift_predtime])\n",
    "    # print(model.summary())\n",
    "    model.compile(loss=['binary_crossentropy', 'mse'], loss_weights=[1, 0.00002],\n",
    "                  optimizer=rmsprop)\n",
    "    # filepath = \"weights/weights-improvement-{epoch:02d}-{loss:.2f}.hdf5\"\n",
    "    # checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "    # callbacks_list = [EarlyStopping(monitor='loss', patience=1,mode='min'),checkpoint]\n",
    "\n",
    "    print(\"model fitting - Hierachical attention network for cyberbullying detection\")\n",
    "\n",
    "    model.fit([x_train, post_train, zeros_train], [y_train, time_train], batch_size=64,\n",
    "              epochs=25, verbose=1)\n",
    "    yp = model.predict([x_val, post_test, zeros_test], verbose=1)\n",
    "    ypreds = yp[0]\n",
    "    ypreds = np.argmax(ypreds, axis=1)\n",
    " #print y_single\n",
    "    #print ypred\n",
    "    f1=precision_recall_fscore_support(y_single.astype(int), ypreds)   # <==\n",
    "    auc=roc_auc_score(y_single.astype('int'), ypreds)  #<==\n",
    "    f1 = precision_recall_fscore_support(y_single.astype(int), ypreds)  # <==\n",
    "    auc = roc_auc_score(y_single.astype('int'), ypreds)  # <== category\n",
    "    end_time = process_time()\n",
    "    cpu_time = end_time - start_time\n",
    "    print(\"cpu_time:\")\n",
    "    print(cpu_time)\n",
    "    print(\"f1:\")\n",
    "    print(f1)\n",
    "    print(\"auc:\")\n",
    "    print(auc)\n",
    "    HAN_TIME.append(cpu_time)\n",
    "    HAN_AUC.append(auc)\n",
    "    HAN_f1.append(f1[2][1])\n",
    "    HAN_reca.append(f1[1][1])\n",
    "    HAN_pre.append(f1[0][1])\n",
    "\n",
    "    #for t-sne visualization\n",
    "    # if j==0:\n",
    "    #     a=model.layers\n",
    "    #     get_representations_test = K.function([model.layers[0].input,model.layers[1].input,model.layers[12].input], [model.layers[6].output])\n",
    "    #     representations_test = get_representations_test([x_val,post_test,zeros_test])[0]\n",
    "    #     representation_dict = {\n",
    "    #         'representations': representations_test,\n",
    "    #         'labels': y_single\n",
    "    #     }\n",
    "    #\n",
    "    #     with open('HANCD_Tem_results.pickle', 'wb') as handle:\n",
    "    #         pickle.dump(representation_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    # K.clear_session()\n",
    "\n",
    "print(HAN_AUC)\n",
    "print(HAN_f1)\n",
    "print(HAN_pre)\n",
    "print(HAN_reca)\n",
    "print(HAN_TIME)\n",
    "print (\"TIME\",np.mean(HAN_TIME), np.std(HAN_TIME))\n",
    "print (\"AUC\",np.mean(HAN_AUC), np.std(HAN_AUC))\n",
    "print (\"f1\", np.mean(HAN_f1), np.std(HAN_f1))\n",
    "print (\"precision\",np.mean(HAN_pre), np.std(HAN_pre))\n",
    "print (\"recall\", np.mean(HAN_reca), np.std(HAN_reca))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2beea49-b28e-4960-a7ad-a1a516ed314a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T03:56:50.337603Z",
     "iopub.status.busy": "2023-05-28T03:56:50.336881Z",
     "iopub.status.idle": "2023-05-28T03:56:50.414668Z",
     "shell.execute_reply": "2023-05-28T03:56:50.412113Z",
     "shell.execute_reply.started": "2023-05-28T03:56:50.337541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_19\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_38 (InputLayer)          [(None, 192, 22)]    0           []                               \n",
      "                                                                                                  \n",
      " time_distributed_9 (TimeDistri  (None, 192, 202)    4286200     ['input_38[0][0]']               \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " input_40 (InputLayer)          [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " transformer_block_19 (Transfor  (None, 192, 202)    246034      ['time_distributed_9[0][0]']     \n",
      " merBlock)                                                                                        \n",
      "                                                                                                  \n",
      " dense_168 (Dense)              (None, 30)           120         ['input_40[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d_19 (G  (None, 202)         0           ['transformer_block_19[0][0]']   \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 30)          120         ['dense_168[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_167 (Dense)              (None, 200)          40600       ['global_average_pooling1d_19[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 30)           0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " dense_166 (Dense)              (None, 192, 1)       202         ['transformer_block_19[0][0]']   \n",
      "                                                                                                  \n",
      " concatenate_29 (Concatenate)   (None, 230)          0           ['dense_167[0][0]',              \n",
      "                                                                  'activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 192, 1)      4           ['dense_166[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_169 (Dense)              (None, 2)            460         ['concatenate_29[0][0]']         \n",
      "                                                                                                  \n",
      " input_39 (InputLayer)          [(None, 1, 1)]       0           []                               \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 192, 1)       0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 2)           8           ['dense_169[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate_28 (Concatenate)   (None, 193, 1)       0           ['input_39[0][0]',               \n",
      "                                                                  'activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 2)            0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " lambda_39 (Lambda)             (None, 192, 1)       0           ['concatenate_28[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,573,748\n",
      "Trainable params: 4,573,682\n",
      "Non-trainable params: 66\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9755a78a-1238-4016-8911-e2ad435fdfec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T03:57:03.290318Z",
     "iopub.status.busy": "2023-05-28T03:57:03.289589Z",
     "iopub.status.idle": "2023-05-28T03:57:03.329722Z",
     "shell.execute_reply": "2023-05-28T03:57:03.327982Z",
     "shell.execute_reply.started": "2023-05-28T03:57:03.290255Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_23 (InputLayer)          [(None, 22)]         0           []                               \n",
      "                                                                                                  \n",
      " lambda_24 (Lambda)             (None, 20)           0           ['input_23[0][0]']               \n",
      "                                                                                                  \n",
      " token_and_position_embedding_6  (None, 20, 200)     4004000     ['lambda_24[0][0]']              \n",
      "  (TokenAndPositionEmbedding)                                                                     \n",
      "                                                                                                  \n",
      " transformer_block_12 (Transfor  (None, 20, 200)     242000      ['token_and_position_embedding_6[\n",
      " merBlock)                                                       0][0]']                          \n",
      "                                                                                                  \n",
      " att_layer_11 (AttLayer)        (None, 200)          40400       ['transformer_block_12[0][0]']   \n",
      "                                                                                                  \n",
      " lambda_25 (Lambda)             (None, 2)            0           ['input_23[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_16 (Concatenate)   (None, 202)          0           ['att_layer_11[0][0]',           \n",
      "                                                                  'lambda_25[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,286,400\n",
      "Trainable params: 4,286,400\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sentEncoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a567bae-5b16-49c3-b75f-c09071cbffee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
